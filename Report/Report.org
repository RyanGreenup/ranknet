#+TITLE: Implementation of Ranknet
:PREAMBLE:
#+OPTIONS: broken-links:auto todo:nil H:9 tags:t tex:t
#+STARTUP: overview
#+AUTHOR: Ryan Greenup
#+PLOT: title:"Citas" ind:1 deps:(3) type:2d with:histograms set:"yrange [0:]"
#+TODO: TODO IN-PROGRESS WAITING DONE
#+CATEGORY: TAD
:END:
:HTML:
#+INFOJS_OPT: view:info toc:3
#+HTML_HEAD_EXTRA: <link rel="stylesheet" type="text/css" href="./resources/style.css">
# #+CSL_STYLE: /home/ryan/Templates/CSL/nature.csl
:END:
:R:
#+PROPERTY: header-args:R :session TADMain :dir ./ :cache yes :eval never-export :exports both
#+PROPERTY: :eval never
# exports: both (or code or whatever)
# results: table (or output or whatever)
:END:
:LATEX:
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper,11pt,twoside]
#+LATEX_HEADER: \IfFileExists{./resources/style.sty}{\usepackage{./resources/style}}{}
#+LATEX_HEADER: \IfFileExists{./resources/referencing.sty}{\usepackage{./resources/referencing}}{}
#+LATEX_HEADER: \addbibresource{../resources/references.bib}
#+LATEX_HEADER: \usepackage[mode=buildnew]{standalone}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{decorations.fractals}
#+LATEX_HEADER: \usetikzlibrary{lindenmayersystems}
:END:
@@latex: \newpage @@

* Introduction
  Ranknet is an approach to /Machine-Learned Ranking (often referred to
  as "/Learning to Rank/" cite:liuLearningRankInformation2009) that
  began development at Microsoft from 2004 onwards
  cite:christopherburgesRankNetRankingRetrospective2015, although
  previous work in this area had already been undertaken as early as
  the 90s (see generally
  cite:fuhrProbabilisticModelsInformation1992,fuhrOptimumPolynomialRetrieval1989,fuhrProbabilisticModelsInformation1992,geyInferringProbabilityRelevance1994,wongLinearStructureInformation1988).
  These earlier models did not, however, perform well compared to more modern
  machine learning techniques 
  [[cite:manningIntroductionInformationRetrieval2008][\S 15.5]].

  Information retrieval is an area that demands effective ranking of
  queries, although straight-forward tools such as =grep=, relational
  databases (e.g. sqlite, MariaDB, PostgreSql) and NoSQL (e.g. CouchDB,
  MongoDB) can be used to retrieve documents with matching characters
  and words, these methods do not perform well in real word tasks
  across large collections of documents because they do not provide
  any logic to rank results (see generally
  cite:viksinghComparisonOpenSource2009).


* Motivation

  Search Engines implement more sophisticated techniques to rank
  results, one such example being TF-IDF weighting
  cite:martyschochBleveSearchDocumentation , well established
  search engines such as /Apache Lucene/
  cite:apachesoftwarefoundationLearningRankApache2017 and /Xapian/
  cite:jamesaylettGSoCProjectIdeasLearningtoRankStabilisationXapian2019,
  however, 
  are implementing Machine-Learned Ranking in order to improve results.

  This paper hopes to serve as a general introduction to the implementation
  of the Ranknet technique to facilitate developers of younger search engines in
  more modern languages (i.e. =Go= and =Rust=). 
  This is important because these more modern languages are more
  accessible cite:huntThesisSubmittedPartial
  and memory safe cite:perkelWhyScientistsAre2020 than C/C++
  respectfully, without significantly impeding performance; this will
  encourage contributors from more diverse backgrounds and hence
  improve the quality of profession-specific tooling.

  
  For a non-comprehensive list of actively maintained search engines,
  see \S [[#search-engines-list]] of the appendix.

* Implementation
  :PROPERTIES:
  :CUSTOM_ID: implementation
  :END:

  

    # A lot of data cannot be clearly categorised or quantified even if there
    # is a capacity to compare different samples, the motivating example
    # is a collection of documents, it might be immediately clear to the
    # reader which documents are more relevant than others, even if the
    # reader would not be able to quantify a "relevance score" for each
    # document.

    # By training a model to identify a more relevant document, a ranking
    # can be applied to the data.

    # An example of this might be identifying documents in a companies
    # interwiki that are relevant for new employees, by training the model
    # to rank whether one document is more relevant than an other,
    # ultimately an ordered list of documents most relevant for new
    # employees could be created.


  #  Neural Networks 

  # Ranking/ is the process of applying machine learning algorithms to
  # ranking problems, it .

  # This implementation will first apply the approach to a simple data
  # set so as to clearly demonstrate that the approach works, following
  # that the model will be extended to support wider and more complex
  # data types before finally being implemented on a corpus of documents.

** Neural Networks

   The Ranknet method is typically implemented using a Neural Network[fn:3],
   although other machine learning techniques can also be used [[cite:christopherburgesRankNetRankingRetrospective2015][p. 1]].

   Neural Networks are essentially a collection of different
   regression models and classifiers that are fed into one another to create a
   non-linear classifier, a loss function is used to measure the
   performance of the model with respect to the parameters
   (e.g. RMSE [fn:1] or BCE [fn:2]) and the parameters are adjusted so
   as to reduce this error by using the /Gradient Descent Technique/
   (although there are other optimisation algorithms such as RMSProp
   and AdaGrad cite:mukkamalaVariantsRMSPropAdagrad2017 that can be
   shown to perform better cite:bushaevUnderstandingRMSpropFaster2018). The specifics of
   Neural Networks are beyond the scope of this paper (see
   cite:hmkcodeBackpropagationStepStep or more generally cite:pictonNeuralNetworks1994).

*** The Ranknet Method

   The Ranknet method is concerned with a value \(p_{ij}\) that
   measures the probability that an observation \(i\) is ranked higher
   than an observation \(j\).

   A Neural Network (\(n\)) is trained to return a value
   \(s_k\) from a feature vector \(\mathbf{X}_k\):

   \[n(\mathbf{X}_i) = s_i \quad \exists k\]
  So as to minimise the error of:


  \[
  p_{ij} = \frac{1}{1+e^{\sigma \cdot (s_i-s_j)}} \quad \exists \sigma
  \in \mathbb{R}
  \]
  



 # \begin{align} 
 #  p_{ij} &= \mathrm{sig}\left(\sigma, (s_i-s_j) \right) \quad \exists \sigma \in \mathbb{R} \\
 #  &\text{where:} \nonumber \\
 #  &\quad  \mathrm{sig}\left(\sigma, x\right) = \frac{1}{1+e^{\sigma \cdot x}} 
 # \end{align} 
  
    
    
**** Version Control
     The implementation in this section (\S [[#implementation)]] corresponds to the =walkthrough= branch
     of the =git= repository used in production of this work, id values
     (e.g. =:08db5b0:=) will be appended to titles to denote specific
     changes made in that section. See \S [[#version-control-repo]] for
     more specific guidance.


     
**** Code listings     
     The code listings provided will use a standard set of import
     statements (see \S [[#standard-import]] ) and so they will be
     omitted from the listings, for more comprehensive guidance on
     implementing this code refer to the [[https://crmds.github.io/CRMDS-HDR-Training-2020/][documentation page]][fn:5] that
     accompanies the =git= repo.

** TODO Creating Data                                                           :cf9ab26:
    The first step is to create a simple data set and design a neural
    network that can classify that data set, the data set generated
    should have two classes of data (this could be interpreted as
    relevant and irrelevant documents given the features or principle
    components of a data set), this can be implemented using sci kit
    learn as shown below and visualized[fn:6] in figure [[sim-data]].[fn:13]


    In order to fit a Neural Network the /PyTorch/ package can be used
    cite:NEURIPS2019_9015, this will allow the gradients of the neural
    network to be calculated numerically without needing to solve for
    the partial derivatives, hence the data will need to be in the
    form of tensors.

    # #+NAME: sample-data-plot
    # #+CAPTION: Generate Sample of Data for Classification
    #+begin_src python
      def make_data(create_plot=False, n=1000, dtype=torch.float, dev="cpu", export=""):
	  X, y = datasets.make_blobs(n, 2, 2, random_state=7)
	  # X, y = datasets.make_moons(n_samples=n, noise=0.1, random_state=0) # Moons Data for later

	  # Save the data somewhere if necessary
	  if export != "":
	      export_data(X, y, export)

	  # Reshape the data to be consistent
	  y = np.reshape(y, (len(y), 1))  # Make y vertical n x 1 matrix.

	  # -- Split data into Training and Test Sets --------------------
	  data = train_test_split(X, y, test_size=0.4)

	  if(create_plot):
	      # Create the Scatter Plot
	      plt.scatter(X[:, 0], X[:, 1], c=y)
	      plt.title("Sample Data")
	      plt.show()

	  # Make sure we're working with tensors not mere numpy arrays
	  torch_data = [None]*len(data)
	  for i in range(len(data)):
	      torch_data[i] = torch.tensor(data[i], dtype=dtype, requires_grad=False)

	  return torch_data

      # Set Torch Parameters
      dtype = torch.float
      dev = test_cuda()

      # Generate the Data
      X_train, X_test, y_train, y_test = make_data(
	  n=int(300/0.4), create_plot=True, dtype=dtype, dev=dev, export = "/tmp/simData.csv")
    #+end_src


    #+BEGIN_SRC R :exports results :results output graphics file :file ./media/SimulatedData.png 
      library(tidyverse)

      data  <- read_csv("/tmp/file.csv")
      myplot <-  ggplot(data, aes(x = x1, y = x2, col = factor(y))) +
			geom_point(size = 3) +
			theme_classic() +
			labs(col = "Relevance", x = "PC1", y = "PC2",
			     title = "Simulated Data")

      ggsave(myplot, filename = "./media/SimulatedData.png",  bg = "transparent")
    #+END_SRC

    #+NAME: sim-data
    #+CAPTION: Generated data, output classes denote document relevance and the axis features or principle components
    #+attr_html: :width 400px
    #+attr_latex: :width 0.4\textwidth 
    #+RESULTS[31b82663f9f121e6d24165834f8eeba4b8f4fc8a]:
    [[file:./media/SimulatedData.png]]

** Creating a Neural Network                                                    :7291112:
   :PROPERTIES:
   :CUSTOM_ID: creating-neural-network
   :END:
   A Neural Network model can be designed as a class, here a 2-layer
   model using Sigmoid functions has been described, this design was
   chosen for it's relative simplicity:

   #+begin_src python
     class three_layer_classification_network(nn.Module):
         def __init__(self, input_size, hidden_size, output_size, dtype=torch.float, dev="cpu"):
	     super(three_layer_ranknet_network, self).__init__()
	     self.wi = torch.randn(input_size, hidden_size,
				   dtype=dtype,
				   requires_grad=True,
				   device=dev)
	     self.wo = torch.randn(hidden_size, output_size,
				   dtype=dtype,
				   requires_grad=True,
				   device=dev)

	     self.bi = torch.randn(hidden_size,
				   dtype=dtype,
				   requires_grad=True,
				   device=dev)
	     self.bo = torch.randn(output_size,
				   dtype=dtype,
				   requires_grad=True,
				   device=dev)

	     self.σ = torch.randn(1, dtype=dtype, requires_grad=True, device=dev)

	     self.losses = []       # List of running loss values
	     self.trainedQ = False  # Has the model been trained yet?

         def forward(self, x):
             x = torch.matmul(x, self.wi).add(self.bi)
             x = torch.sigmoid(x)
             x = torch.matmul(x, self.wo).add(self.bo)
             x = torch.sigmoid(x)
             return x

         def loss_fn(self, x, y):
             y_pred = self.forward(x)
             return torch.mean(torch.pow((y-y_pred), 2))

         def misclassification_rate(self, x, y):
             y_pred = (self.forward(x) > 0.5)
             return np.average(y != y_pred)
   #+end_src
 
   A model can then be instantiated, a =2-3-1=
   model has, arbitrarily, been implemented in this case:[fn:7]

   #+begin_src python :results output
     # Set Seeds
     torch.manual_seed(1)
     np.random.seed(1)

     # Set Torch Parameters
     dtype = torch.float
     dev = test_cuda()

     # Make the Data
     X_train, X_test, y_train, y_test = make_data(
	 n=100, create_plot=True, dtype=dtype, dev=dev)

     # Create a model object
     model = three_layer_classification_network(
	 input_size=X_train.shape[1], hidden_size=2, output_size=1, dtype=dtype, dev=dev)

     # Send some data through the model
     print("\nThe Network input is:\n---\n")
     print(X_train[7,:], "\n")
     print("The Network Output is:\n---\n")
     print(model.forward(X_train[7,:]).item(), "\n")

   #+end_src

   #+begin_example
     The Network input is:
     ---

     tensor([-1.5129,  2.9332]) 

     The Network Output is:
     ---

     0.22973690927028656 
   #+end_example
   
** Train the Model with Gradient Descent                                        :7d46636:
   Now that the model has been fit, a method to train the model can be
   implmented [fn:8]:
   #+begin_src python
     class three_layer_classification_network(nn.Module):
	 # __init__ method goes here, see above
	 # ...
	 # ...

	 def train(self, x, target, η=30, iterations=2e4):
	     bar = Bar('Processing', max=iterations) # progress bar
	     for t in range(int(iterations)):

		 # Calculate y, forward pass
		 y_pred = self.forward(x)

		 # Measure the loss
		 loss = self.loss_fn(x, target)

		 # print(loss.item())
		 self.losses.append(loss.item())

		 # Calculate the Gradients with Autograd
		 loss.backward()

		 with torch.no_grad():
		     # Update the Weights with Gradient Descent 
		     self.wi -= η * self.wi.grad; self.wi.grad = None
		     self.bi -= η * self.bi.grad; self.bi.grad = None
		     self.wo -= η * self.wo.grad; self.wo.grad = None
		     self.bo -= η * self.bo.grad; self.bo.grad = None
		     self.σ  -= η * self.σ.grad;  self.σ.grad = None
		 bar.next()
	     bar.finish()
		     # ; Zero out the gradients, they've been used

	 # Rest of the Class Definition Below ...VVV...
   #+end_src

   With this definition the model can hence be trained in order to
   produce meaningful classifications, as shown below, due to the
   simplicity of the data set, this model classifies the
   points perfectly on the testing set, the training error 
   over time is shown in figure [[training-error-1]].

   #+begin_src python
     # Make the Data
     X_train, X_test, y_train, y_test = make_data(
	 n=100, create_plot=True, dtype=dtype, dev=dev)

     # Create a model object
     model = three_layer_classification_network(
	 input_size=X_train.shape[1], hidden_size=2, output_size=1, dtype=dtype, dev=dev)

     # Train the Model
     model.train(X_train, y_train, η=1e-2, iterations=10000)

     # Plot the losses
     plt.plot(model.losses)
     plt.title("Losses at each training iteration")
     plt.show()

     print("The testing misclassification rate is:\n")
     print(model.misclassification_rate(X_test, y_test))
   #+end_src


   #+NAME: training-error-1
   #+CAPTION: Training error, given by \(l\left( x \right) = \sum^{n}_{i= 1} \left[ \left( x_i - f\left( x_i \right)  \right)^2  \right]\), at each iteration of training
   #+attr_html: :width 50 px
   #+attr_latex: :width 0.3\textwidth
   [[./media/loss_function_initial_nn.png]]

** Implement Ranknet                                                            :f25f376:05df04f:
   Now that the model can classify the data, the implementation will
   be modified to:

   - Measure loss using a BCE function which is reported in the
     literature
     cite:christopherburgesRankNetRankingRetrospective2015,christopherburgesRankNetLambdaRankLambdaMART2010 to perform
     better for Ranking problems.
   - Modify the model so that it operates pairwise, such that:
     1. Two points are identified, sent through the neural network and
        two values returned:
	  \begin{align}
	  s_i = n(\mathbf{X}_i) \label{eq:forward_single1}\\
	  s_j = n(\mathbf{X}_j) \label{eq:forward_single2}
	  \end{align}
	The network previously created can be adapted for this and
        hence the method will be renamed to =forward_single= and this
        will represent function \(n()\) implemented in
        eqref:eq:forward_single1 and eqref:eq:forward_single2
     2. These values will be combined to give a single value which is
        intended to measure the model confidence:[fn:9]

	\begin{align}
	\hat{P}_{ij} &= \mathrm{sig}\left(\sigma, (s_i-s_j)\right), \quad
	\exists \sigma \in \mathbb{R} \\
	&= \frac{1}{1+e^{\sigma \cdot (s_i-s_j)}} \label{eq:sig-comb}
	\end{align}
     3. The range of eqref:eq:sig-comb  is the interval \(\hat{P}_{ij} =
        \left[0, 1\right]\), let \(\bar{P}_{ij}\) be the known
        probability[fn:10] that \(\mathbf{X}_i \triangleright
        \mathbf{X}_j\), the simulated data has a boolean range of
        \(\bar{P}_{ij} \in \left\{0, 1\right\}\), this can be recast
        to \(\{-1, 0, 1\}\) and then linearly scaled to \(\left[0,
        1\right]\) like so:

	\begin{align}
	\bar{P}_{ij} & \leftarrow p_i - p_j \\
	\bar{P}_{ij} & \leftarrow \frac{1+\bar{P}_{ij}}{2}
	\end{align}


   These modifications only need to be made to the neural network
   class like so:

   #+begin_src python
     class three_layer_ranknet_network(nn.Module):
	 # __init__ method
	 # ...
	 # ...

	 def forward(self, xi, xj):
	     si = self.forward_single(xi)
	     sj = self.forward_single(xj)
	     out = 1 / (1 + torch.exp(-self.σ * (si - sj)))  
	     return out

	 def forward_single(self, x):
	     x = torch.matmul(x, self.wi).add(self.bi)
	     x = torch.sigmoid(x)
	     x = torch.matmul(x, self.wo).add(self.bo)
	     x = torch.sigmoid(x)

	     return x

	 def loss_fn(self, xi, xj, y):
	     y_pred = self.forward(xi, xj)
	     loss = torch.mean(-y * torch.log(y_pred) -
			       (1 - y) * torch.log(1 - y_pred))
	     return loss

	def pairwise(iterable):
	    "pairwise([1,2,3,4]) --> [(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]"
	    s = list(iterable)
	    pair_iter = chain.from_iterable(combinations(s, r) for r in [2])
	    return pair_iter

   #+end_src

   The training method must be adapted to interact with these changes
   like so:[fn:11]

   #+begin_src python
     class three_layer_ranknet_network(nn.Module):
	 # __init__ method
	 # ...
	 # ...
	 def train(self, x, target, η=1e-2, iterations=4e2):
	     self.trainedQ = True
	     # Create a progress bar
	     bar = Bar('Processing', max=iterations)
	     # Train for a number of iterations
	     for t in range(int(iterations)):
		 sublosses = []
                 # Loop over every pair of values
		 for pair in pairwise(range(len(x) - 1)):
		     xi, yi = x[pair[0], ], target[pair[0]]
		     xj, yj = x[pair[1], ], target[pair[1]]

		     # encode from {0, 1} to {-1, 0, 1}
		     y = yi - yj

		     # Scale between {0,1}
		     y = 1 / 2 * (1 + y)

		     # Calculate y, forward pass
		     y_pred = self.forward(xi, xj)

		     # Measure the loss
		     loss = self.loss_fn(xi, xj, y)
		     sublosses.append(loss.item())

		     # Calculate the Gradients with Autograd
		     loss.backward()

		     # Update the Weights with Gradient Descent
		     # ; Zero out the gradients, they've been used
		     with torch.no_grad():
			 self.wi -= η * self.wi.grad; self.wi.grad = None
			 self.bi -= η * self.bi.grad; self.bi.grad = None
			 self.wo -= η * self.wo.grad; self.wo.grad = None
			 self.bo -= η * self.bo.grad; self.bo.grad = None
			 self.σ  -= η * self.σ.grad ; self.σ.grad  = None

		 self.losses.append(np.average(sublosses))
		 bar.next()
	     bar.finish()
	     self.threshold_train(x, target, plot=False)
   #+end_src

   This can then be implemented as before, the loss function is
   provided at figure [[ranknet-loss]]. 

   #+begin_src python
     # Make the Data
     X_train, X_test, y_train, y_test = make_data(
	 n=30, create_plot=True, dtype=dtype, dev=dev)

     # Create a model object
     model = three_layer_ranknet_network(
	 input_size=X_train.shape[1], hidden_size=2, output_size=1, dtype=dtype, dev=dev)

     # Train the Model
     model.train(X_train, y_train, η=1e-1, iterations=1e2)

     # Save the losses
     np.savetxt(fname="/tmp/losses.csv", X=model.losses, delimiter=',')

   #+end_src
   
    #+BEGIN_SRC R :exports results :results output graphics file :file ./media/ranknet_loss.png 
      library(tidyverse)

      data <- read.csv(file = "/tmp/losses.csv", header = FALSE, sep = ",")[1]
      data$iteration <- 1:nrow(data)
      names(data) <- c("losses", "iteration")

      losses_plot <- ggplot(data, aes(x = iteration, y = losses)) +
	  geom_line(size = 1, color = "indianred") +
	  theme_classic() +
	  labs(x = "Training Iteration", y = "Loss measured using BCE",
	  title = "Training Loss at each iteration for Ranknet")

      ggsave(losses_plot, filename = "./media/ranknet_loss.png",  bg = "transparent")
    #+END_SRC

    #+NAME: ranknet-loss
    #+CAPTION: BCE training loss at each iteration for the Ranknet method.
    #+attr_html: :width 400px
    #+attr_latex: :width 0.4\textwidth
    #+RESULTS[c869c9ccd6760c95180c63874b696369ed59b481]:
    [[file:./media/ranknet_loss.png]]

** Implement sorting                                                            :99b390a:7d46636:
   One of the difficulties in implementing this, however, is that it
   is not simple to determine whether or not the model has classified
   the data well,[fn:12] In order to address this the model can be
   implemented to sort the data by ranked values and then
   visualised. To implement this a derivative of the /quicksort/
   algorithm was chosen as a sorting function
   cite:hoareAlgorithm64Quicksort1961, this was implemented by
   adapting code already available in the literature
   [[cite:kernighanProgrammingLanguage1988][\S 4.10]] and online
   cite:PythonProgramQuickSort2014:  

   #+begin_src python
     def split(values, left, right, data, model):
	 # Define the leftmost value
	 l = (left-1)
	 # Set the right value as the pivot
	 pivot = values[right]  # TODO The pivot should be random

	 for q in range(left, right):
	     # Only move smaller values left
	     if leq(values[q], pivot, data, model):
		 # +1 next left element
		 l = l+1
		 # Swap the current element onto the left
		 values[l], values[q] = values[q], values[l]

	 # Swap the pivot value into the left position from the right
	 values[l+1], values[right] = values[right], values[l+1]
	 return (l+1)


     def qsort(values, left, right, data, model):
	 if len(values) == 1:
	     return values
	 if right > left:
	     # pi is the index of where the pivot was moved to
	     # It's position is now correct
	     pi = split(values, left, right, data, model)

	     # Do this again for the left and right parts
	     qsort(values, left, pi-1, data, model)
	     qsort(values, pi+1, right, data, model)

     import random

     def leq(a, b, data, model):
	 score = model.forward(data[a, :], data[b, :])
	 if score <= 0.5:
	     return True
	 if score > 0.5:
	     return False

	     if (a < b):
		 return True
	     else:
		 return False


     if DEBUG:
	 for i in range(3):
	     import random
	     values = random.sample(range(9), 7)
	     n = len(values)
	     print(values)
	     qsort(values, 0, n-1, data, model)
	     print("==>", values)

   #+end_src

   The data can then be plotted, as in figure [[ordered-blobs]] and exported like so:[fn:14]

   #+begin_src python
     # Main Function
     def main():
	 # Make the Data
	 X_train, X_test, y_train, y_test = make_data(n=100,
						      create_plot=True,
						      dtype=dtype,
						      dev=dev)

	 # Create a model object
	 model = three_layer_ranknet_network(input_size=X_train.shape[1],
					     hidden_size=2,
					     output_size=1,
					     dtype=dtype,
					     dev=dev)

	 # Train the Model
	 model.train(X_train, y_train, η=1e-1, iterations=1e2)

	 # Visualise the Training Error
	 plot_losses(model)

	 # Misclassification won't work for ranked data
	 # Instead Visualise the ranking
	 plot_ranked_data(X_test, y_test, model)


     def plot_losses(model):
	 plt.plot(model.losses)
	 plt.title("Cost / Loss Function for Iteration of Training")
	 plt.show()


     def plot_ranked_data(X, y, model):
	 # Create a list of values
	 n = X.shape[0]
	 order = [i for i in range(n)]
	 # Arrange that list of values based on the model
	 quicksort(values=order, left=0, right=(n - 1), data=X, model=model)
	 print(order)

	 ordered_data = X[order, :]
	 y_ordered = y[order]

	 np.savetxt("/tmp/ordered_data.csv", X=ordered_data.numpy(), delimiter=',')

	 p = plt.figure()
	 for i in range(len(ordered_data)):
	     plt.text(ordered_data[i, 0], ordered_data[i, 1], i)
	 plt.scatter(ordered_data[:, 0], ordered_data[:, 1], c=y_ordered)
	 plt.title("Testing Data, with ranks")
	 plt.show()


     if __name__ == "__main__":
	 main()
   #+end_src

   
    #+BEGIN_SRC R :exports results :results output graphics file :file media/ordered_blobs.png
	library(tidyverse)

	data <- read.csv(file = "/tmp/ordered_data.csv", header = FALSE, sep = ",")
	data$order <- 1:nrow(data)
	names(data) <- c("PC1", "PC2", "rank")
	data

	ordered_plot <- ggplot(data, aes(x = PC1, y = PC2)) +
	    geom_label(aes(label = rank), nudge_x = 0.0, nudge_y = 0.0, size = 5) +
	    geom_point(aes(col = rank), size = 15, alpha = 0.4) +
	    theme_classic() +
	    labs(x = "Training Iteration", y = "Loss measured using BCE",
	    title = "Training Loss at each iteration for Ranknet") + 
	    guides(col = FALSE, alpha = FALSE, size = FALSE) +
	    scale_color_gradient2(mid="white", high="red", space ="Lab" )

      ggsave(ordered_plot, filename = "./media/ordered_blobs.png",  bg = "transparent")

    #+END_SRC

    #+NAME: ordered-blobs
    #+CAPTION: Using Machine Learned Ranking to order the points from most to least relevant
    #+attr_html: :width 400px
    #+attr_latex: :width 0.6\textwidth
    #+RESULTS[c249d180414d32fc6284a4c105f4845e701be68e]:
    [[file:media/ordered_blobs.png]]

*** Visualising Model Performance
    :PROPERTIES:
    :CUSTOM_ID: vis-mod
    :END:
    Although the results in figure [[ordered-blobs]] appear very
    encouraging at first, if the same sorting approach is implemented
    for an untrained model (i.e. a model with random weights), an
    uncomfortably similar, ordered pattern emerges, this is
    shown[fn:15] in figure [[ordered-blobs-untrained]].

    This pattern could be explained by the fact that the model, trained or untrained, 
    is continuous and so the rank of nearby points could lead the
    emergence of an ordered pattern.

    Investigating types of data where the Ranknet model will produce an ordered
    pattern only when trained would represent a logical next step. One
    approach would be to consider the rating of a product (e.g. the
    quality of wine, see cite:cortezModelingWinePreferences2009) and
    train a Ranknet model based only on whether or not one wine is
    better than the next. The order of the returned results could be
    compared with the order of the original dataset as well as a
    random untrained control model in order to evaluate the efficacy
    of the model.


    #+BEGIN_SRC R :exports results :results output graphics file :file media/ordered_blobs_untrained.png 
	library(tidyverse)

	data <- read.csv(file = "/tmp/ordered_data_untrained.csv", header = FALSE, sep = ",")
	data$order <- 1:nrow(data)
	names(data) <- c("PC1", "PC2", "rank")
	data

	ordered_plot <- ggplot(data, aes(x = PC1, y = PC2)) +
	    geom_label(aes(label = rank), nudge_x = 0.0, nudge_y = 0.0, size = 5) +
	    geom_point(aes(col = rank), size = 15, alpha = 0.4) +
	    theme_classic() +
	    labs(x = "Training Iteration", y = "Loss measured using BCE",
	    title = "Training Loss at each iteration for Ranknet") + 
	    guides(col = FALSE, alpha = FALSE, size = FALSE) +
	    scale_color_gradient2(mid="blue", high="white", space ="Lab" )

      ggsave(ordered_plot, filename = "./media/ordered_blobs_untrained.png",  bg = "transparent")

    #+END_SRC

    #+NAME: ordered-blobs-untrained
    #+CAPTION: Using Machine Learned Ranking to order the points from most to least relevant
    #+attr_html: :width 400px
    #+attr_latex: :width 0.6\textwidth
    #+RESULTS[30a515e8f5b11b12f0c5813c215184d538322f58]:
    [[file:media/ordered_blobs_untrained.png]]

   
** TODO Enhancing the Model
   Further enhancements (such as random batches and alternative
   optimisers) were made to the model and alternative datasets
   implemented (see =473dce= \(\rightarrow\) =d11e607=) however the
   results were mixed and not encouraging, rather an alternative type
   of data should first be considered and evaluated, as already
   discussed in \S [[#vis-mod]].

* Further Research
  The implementation of this technique has proved considerably more
  difficult than first perceived, more work is required. In this
  section particular points of improvement are identified.

 
  
** Improve the sorting algorithm
  The "Quicksort" algorithm likely needs a random pivot to be
  efficient cite:timroughgardenQuicksortOverview2017. 

** Evaluate Model Performance
  It is still not clear how the
  performance of Ranknet compares to traditional approaches
  implemented by search engines (see \S [[#search-engines-list]]), further
  study would ideally:

  - Write a program to query a corpus of documents using an existing search engine.
    - Or possibly just implement TF-IDF weighting in order to remove variables.
  - Extend the program to implement machine learned ranking
  - Measure and contrast the performance of the two models to see
    whether there are any significant improvements.

  This could be implemented with TREC datasets
  cite:usnationalinstituteofstandardsandtechnologyTextREtrievalConference
  using a cummulated-gain cost function
  cite:jarvelinCumulatedGainbasedEvaluation2002 as demonstrated in
  previous work cite:viksinghComparisonOpenSource2009.

  
   It is not yet clear:

   1. How this could be applied for a broad range of queries
   2. How to effectively measure the "correctness" of ranked documents

** Evaluate alternative machine learning models
   :PROPERTIES:
   :CUSTOM_ID: machine-learning-models
   :END:
   An open question is whether or not alternative machine learning
   algorithms such as trees and SVMs could be used to fit the Ranknet
   model in an effective fashion, this could be ideal for performance
   concerns as deep neural networks can be resource intensive.

   Another question is how Ranknet compares to simply using
   classification approaches to identify documents that might be
   relevant.  


* Conclusion
  The Ranknet approach to machine-learned ranking looks promising, but
  it is difficult to implement and more study is needed to evaluate
  whether or not it brings significant advantages over traditional
  approaches and whether or not there are effective ways to apply the
  model to search problems for a broad scope of queries.


* Appendix
  
** Search Engines
   :PROPERTIES:
   :CUSTOM_ID: search-engines-list
   :END:
There are many open source search engines available , a cursory review
found the following popular projects:

- [[https://github.com/apache/lucene-solr][Apache lucene/Solr]] (=Java=) cite:apachesoftwarefoundationLearningRankApache2017
  - Implemented by [[https://sourceforge.net/p/docfetcher/code/ci/master/tree/][DocFetcher]] cite:docfetcherdevelopmentteamDocFetcherFastDocument
- [[https://github.com/sphinxsearch/sphinx][Sphinx]] (=C++=) cite:yurischapovSphinxsearchSphinx2021
- [[https://github.com/kevinduraj/xapian-search][Xapian]] (=C++=) cite:ollybettsXapianXapian2021
  - Implemented by [[https://www.lesbonscomptes.com/recoll/][Recoll]] cite:jean-francoisdockesRecollUserManual
- [[https://github.com/cyclaero/zettair][Zettair]] (=C=) cite:jansenCyclaeroZettair2020

More Modern Search engines include:

- [[https://github.com/blevesearch/bleve][Bleve Search]] (=Go=) cite:martyschochBleveSearchDocumentation
- [[https://github.com/go-ego/riot][Riot]] (=Go=) cite:vzGoegoRiot2021
- [[https://github.com/olivernn/lunr.js/][LunrJS]]  (=JS=) cite:nightingaleOlivernnLunrJs2021
- [[https://github.com/andylokandy/simsearch-rs][SimSearch]] (=Rust=) cite:lokAndylokandySimsearchrs2021
- [[https://github.com/tantivy-search/tantivy][Tantivy]] (=Rust=) cite:clementrenaultMeilisearchMeiliSearch2021

  
*** Fuzzy String Match
    Somewhat related are programs that rank string similarity, such programs don't tend
    to perform well on documents however (so for example these would
    be effective to filter document titles but would not be useful for
    querying documents):

    - [[https://github.com/junegunn/fzf][=fzf=]] cite:choiJunegunnFzf2021
    - [[https://github.com/jhawthorn/fzy][=fzy=]] cite:hawthornJhawthornFzy2021
    - [[https://github.com/lotabout/skim][=go-fuzzyfinder=]] cite:ktrKtr0731Gofuzzyfinder2021
    - [[https://github.com/peco/peco][=peco=]] cite:lestrratPecoPeco2021
    - [[https://github.com/lotabout/skim][Skim]] cite:zhangLotaboutSkim2021
    - [[https://github.com/lotabout/skim][Swiper]] cite:krehelAboaboSwiper2021

** Import Statements
   :PROPERTIES:
   :CUSTOM_ID: standard-import
   :END:
The following import statements were included, where used, [fn:4]
separate scripts were used to make the model as modular as possible,
such corresponding inputs have also been listed:

#+begin_src python
  # Import Packages
  from itertools import chain
  from itertools import combinations
  from itertools import tee
  from progress.bar import Bar
  import math as m
  import matplotlib.pyplot as plt
  import numpy as np
  import random
  import sys
  import sys
  import torch
  import torch
  from torch import nn

  # Sepereate Scripts lcated below main
  from ranknet.test_cuda import test_cuda
  from ranknet.make_data import make_data
  from ranknet.neural_network import three_layer_ranknet_network
  from ranknet.quicksort import quicksort
#+end_src
   
** Export Data Method
   :PROPERTIES:
   :CUSTOM_ID: export-data-function
   :END:
   The data was exported by printing the values to a text file like
   so:

   #+begin_src python
     def export_data(X, y, export):
	 try:
	     os.remove(export)
	     print("Warning, given file was over-written")
	 except:
	     pass

	 with open(export, "a") as f:
	     line = "x1, x2, y \n"
	     f.write(line)
	     for i in (range(X.shape[0])):
		 line = str(X[i][0]) + ", " + str(X[i][1]) + ", " + str(y[i]) + "\n"
		 f.write(line)
	 print("Data Exported")


   #+end_src

** Version Control Repository
   :PROPERTIES:
   :CUSTOM_ID: version-control-repo
   :END:

   The =git= repository used in production of this code is currently
   available on /GitHub/ at [[https://github.com/CRMDS/CRMDS-HDR-Training-2020][github.com/CRMDS/CRMDS-HDR-Training-2020]], in
   order to get a local copy, execute the following commands (=bash=): 

   #+begin_src bash
     # Clone the repository
     git clone https://github.com/CRMDS/CRMDS-HDR-Training-2020

     # Change to the subdirectory
     cd CRMDS-HDR-Training-2020/ranknet

     # Checkout the Walkthrough branch
     git checkout walkkthrough

     # list the changes
     git log
   #+end_src

   Consider the use of tools like [[https://magit.vc/][magit]] cite:MagitMagit2008 and
   [[https://github.com/emacsmirror/git-timemachine][git-timemachine]] cite:peterstiernstromEmacsmirrorGittimemachine2014 (or
   [[https://marketplace.visualstudio.com/items?itemName=eamodio.gitlens][GitLens]] cite:amodioEamodioVscodegitlens2016 and [[https://marketplace.visualstudio.com/items?itemName=bee.git-temporal-vscode][git-temporal]]
   cite:beewilkersonGittemporalGittemporalMono2018 in VsCode) in order
   to effectively preview the changes at each step, alternatively a
   pager like [[https://github.com/sharkdp/bat][bat]] cite:peterSharkdpBat2018 can also be used with something like [[https://github.com/junegunn/fzf][fzf]]
   cite:choiJunegunnFzf2021 like so:

   #+begin_src bash
     git log | grep '^commit' | sed 's/^commit\ //' |\
         fzf --preview 'git diff {}^! |\
          bat --color always'  
   #+end_src

*** Version Control Log for Walkthrough
    :PROPERTIES:
    :CUSTOM_ID: git-log
    :END:

 | */Commit ID/* | */Message/*                                              |
 |-------------+--------------------------------------------------------|
 | =ed5f4cf=     | /Initial Commit/                                         |
 | =075acf9=     | /Walkthrough Initial Commit/                             |
 | =cf9ab26=     | /Generate data to use for classification/                |
 | =7291112=     | /Create a Neural Network Model/                          |
 | =7d46636=     | /Implement gradient descent to train neural network/     |
 | =f25f376=     | /Adapt Neural Network to perform Ranking/                |
 | =42509ab=     | /Implement sorting algorithm to visualise ranking order/ |
 | =05df04f=     | /Adapt Neural Network to perform Ranking/                |
 | =99b390a=     | /Implement sorting algorithm to visualise ranking order/ |
 | =473dce3=     | /Implement optimizer to replace mere gradient descent/   |
 | =4141e92=     | /Train Model using Batches not entire dataset/           |
 | =a2671a6=     | /Format code to make it more readable/                   |
 | =d11e607=     | /plot and only train on different ranked pairs/          |
   
**** COMMENT Export
    #+begin_example
      commit d11e6076cb1e7838a978158682114948c013b146
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Fri Feb 19 16:34:45 2021 +1100

	  plot and only train on different ranked pairs

      commit a2671a6bd33b0fcb50f83d66326f55181c50ce5a
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Wed Feb 17 17:30:09 2021 +1100

	  Format code to make it more readable

      commit 4141e925f6ff61dc5b95dbcc1556699cb254ee98
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Wed Feb 17 17:29:28 2021 +1100

	  Train Model using Batches not entire dataset

      commit 473dce38554598aee49a4ebe042ce8dd0abfba0c
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Wed Feb 17 16:08:43 2021 +1100

	  Implement optimizer to replace mere gradient descent

      commit 99b390a81a8819205a16cc0df87ac0e1fdb6b267
      Merge: 05df04f 42509ab
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Wed Feb 17 16:07:05 2021 +1100

	  Implement sorting algorithm to visualise ranking order

      commit 05df04f3620e6bcce179ae3d2ad84fc7756e2819
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Wed Feb 17 16:00:12 2021 +1100

	  Adapt Neural Network to perform Ranking

      commit 42509abfe76a8583520c1ad577c28ed49a5cebde
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 16:17:59 2021 +1100

	  Implement sorting algorithm to visualise ranking order

      commit f25f3768b44f884409298f6f62c6bd430bc78574
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 16:12:18 2021 +1100

	  Adapt Neural Network to perform Ranking

      commit 7d46636dd1008bf48e58978d2b075f13a31bd765
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 15:30:37 2021 +1100

	  Implement gradient descent to train neural network

      commit 7291112447daee631ece7583b4e94a57ab428e25
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 15:10:03 2021 +1100

	  Create a Neural Network Model

      commit cf9ab26ae9282f77ffd183bb0d71324280dd5323
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 14:50:01 2021 +1100

	  Generate data to use for classification

      commit 075acf96e24a288acc51f6467ee1c1fb10353805
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 14:42:01 2021 +1100

	  Walkthrough Initial Commit

      commit ed5f4cfdbed3751b8a778c15a542356005222b22
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Fri Jan 8 10:57:30 2021 +1100

	  Initial Commit

    #+end_example


* Footnotes

[fn:15] For Clarity sake the colours have been inverted. 
[fn:14] In this case the plot has been generated by /GGPlot2/ [fn:13] 

[fn:13] Visualisations for this Report were implemented using
=org-babel= cite:dominikOrgModeReference2018 inside /Emacs/
cite:stallmanGNUEmacsManual2002 to call */R/*
cite:rcoreteamLanguageEnvironmentStatistical2021 with /GGPlot2/
cite:wickhamGgplot2ElegantGraphics2016a (and /Tidyverse/
cite:wickhamWelcomeTidyverse2019 generally), the source code for this
is avaliable in the report manuscript available in the =git= repository
available at [[https://github.com/RyanGreenup/ranknet/blob/main/Report/Report.org][github.com/RyanGreenup/ranknet/blob/main/Report/Report.org]]

[fn:12] A naive misclassification method was implemented (=f25f376=),
but it was not very insightful and so was omitted from this report.

[fn:11] Note the definition of the =pairwise= function, this was
incorrectly implemented initially (=f25f376=) and rectified shortly
after (=05df04f=). see \S [[#git-log]]

[fn:10] Note the convention to that \(\triangleleft, \enspace
\triangleright\) denote the ranking of two observations cite:christopherburgesRankNetLambdaRankLambdaMART2010

[fn:9] This value is a measurement of the models "confidence" but
could be extended to represent the "measured probability" of one item
being ranked higher than an other (e.g. the probability that a person
would rank one type of wine as better than the other in a random
sample).
 
[fn:8] This class definition is incomplete and serves only to show the
method definition corresponding to the original class shown in \S
[[#creating-neural-network]]


[fn:7] note that the model has not yet been trained, the weights are
random and the model output is not related to the data at all.

[fn:6] See \S [[#export-data-function]] for the specific method definition used to
export the data to a =csv.=  

[fn:5] [[https://crmds.github.io/CRMDS-HDR-Training-2020/][crmds.github.io/CRMDS-HDR-Training-2020/]]

[fn:4] Including =import= statements where they are not used is fine,
other than complaints from a /linter/ following /PEP/
cite:nickcoghlanPEPStyleGuide2001 (e.g. [[https://pypi.org/project/autopep8/][autopep]]
cite:hattoriAutopep8ToolThat) the code will function just fine.

[fn:3] An early goal of this research was to evaluate the performance
  of different machine learning algorithms to implement the Ranknet
  method, as well as contrasting this with simple classification
  approaches, this research however is still ongoing,  see \S
  [[#machine-learning-models]]

[fn:2] *BCE* /Binary Cross Entropy/ 

[fn:1] *RMSE* /Root Mean Square Error/  
