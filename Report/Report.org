#+TITLE: Implementing of RankNet
:PREAMBLE:
#+OPTIONS: broken-links:auto todo:nil H:9 tags:t tex:t
#+STARTUP: overview
#+AUTHOR: Ryan Greenup
#+PLOT: title:"Citas" ind:1 deps:(3) type:2d with:histograms set:"yrange [0:]"
# #+TODO: TODO IN-PROGRESS WAITING DONE
#+CATEGORY: TAD
:END:
:HTML:
#+INFOJS_OPT: view:info toc:3
#+HTML_HEAD_EXTRA: <link rel="stylesheet" type="text/css" href="./resources/style.css">
# #+CSL_STYLE: /home/ryan/Templates/CSL/nature.csl
:END:
:R:
#+PROPERTY: header-args:R :session TADMain :dir ./ :cache yes :eval never-export :exports both
#+PROPERTY: :eval never
# exports: both (or code or whatever)
# results: table (or output or whatever)
:END:
:LATEX:
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper,11pt,twoside]
#+LATEX_HEADER: \IfFileExists{./resources/style.sty}{\usepackage{./resources/style}}{}
#+LATEX_HEADER: \IfFileExists{./resources/referencing.sty}{\usepackage{./resources/referencing}}{}
#+LATEX_HEADER: \addbibresource{../resources/references.bib}
#+LATEX_HEADER: \usepackage[mode=buildnew]{standalone}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{decorations.fractals}
#+LATEX_HEADER: \usetikzlibrary{lindenmayersystems}
:END:
@@latex: \newpage @@

* Introduction
  Ranknet is an approach to /Machine-Learned Ranking (often refered to
  as "//Learning to Rank//" cite:liuLearningRankInformation2009) that
  began development at Microsoft from 2004 onwards
  cite:christopherburgesRankNetRankingRetrospective2015, although
  previous work in this area had already been undertaken as early as
  the 90s (see generally
  cite:fuhrProbabilisticModelsInformation1992,fuhrOptimumPolynomialRetrieval1989,fuhrProbabilisticModelsInformation1992,geyInferringProbabilityRelevance1994,wongLinearStructureInformation1988)
  these earlier models didn't perform well compared to more modern
  machine learning techniques
  [[cite:manningIntroductionInformationRetrieval2008][\S 15.5]].

  Information retrieval is an area that demands effective ranking of
  queries, although relatively simple tools such as =grep=, relational databases
  such as Sqlite or NoSQL databases like MongoDB can be used to
  retrieve documents with matching characters and words, these methods
  do not perform well in real word tasks across large collections of
  documents because they do not provide any logic to rank results (see generally cite:viksinghComparisonOpenSource2009).

  Search Engines implement more sophisticated techniques to rank
  results, one such example being TF-IDF weighting
  cite:martyschochBleveSearchDocumentation.  [fn:3]

  Many search engine
  Traditional Search-engines such /Apache Lucene/
  cite:apachesoftwarefoundationLearningRankApache2017 and Xapian
  cite:jamesaylettGSoCProjectIdeasLearningtoRankStabilisationXapian2019
  have begun implementing 
  This paper hopes to serve as an introduction to the implementation
  of this technique.

  The Ranknet approach is typically implemented using Neural Networks,
  an early goal of this research was to evaluate the performance of
  different machine learning algorithms to implement the Ranknet
  method, this research however is still ongoing.

  Further Research to look at the implementation of Ranknet for
  documents and comparing different approaches to apply the method to
  on-demand queries is required, although this seems to have been
  implemented by open source Apache Solr project
  cite:michaelalcornIntroductionMachinelearnedRanking, which may
  provide guidance for further study. An open question is how the
  performance of Ranknet performs compared to alternative pre-existing
  methods like Recoll cite:jean-francoisdockesRecollUserManual and
  docfetcher cite:docfetcherdevelopmentteamDocFetcherFastDocument.

  For a non-comprehensive list of actively maintained search engines,
  see \S [[#search-engines-list][Search Engines]] of the appendix.
  
  Ranking/ is the process of applying machine learning algorithms to
  ranking problems, it .
* Motivation
  A lot of data cannot be clearly categorised or quantified even if there
  is a capacity to compare different samples, the motivating example
  is a collection of documents, it might be immediately clear to the
  reader which documents are more relevant than others, even if the
  reader would not be able to quantify a "relevance score" for each
  document.

  By training a model to identify a more relevant document, a ranking
  can be applied to the data.

  An example of this might be identifying documents in a companies
  interwiki that are relevant for new employees, by training the model
  to rank whether one document is more relevant than an other,
  ultimately an ordered list of documents most relevant for new
  employees could be created.
* Implementation
  This implementation will first apply the approach to a simple data
  set so as to clearly demonstrate that the approach works, following
  that the model will be extended to support wider and more complex
  data types before finally being implemented on a corpus of documents.

** Neural Network
   Neural Networks cite:pictonNeuralNetworks1994

   The Ranknet method is typically implemented using a Neural Network,
   although other machine learning techniques can also be used
   [[cite:christopherburgesRankNetRankingRetrospective2015][\s 1]],
   Neural Networks are essentially a collection of different
   regression models that are fed into one another to create a
   non-linear classifier, a loss function is used to measure the
   performance of the model with respect to the parameters
   (e.g. RMSE [fn:1] or BCE [fn:2]) and the parameters are adjusted so
   as to reduce this error by using the /Gradient Descent Technique/
   (although there are other optimisation algorithms such as RMSProp
   and AdaGrad cite:mukkamalaVariantsRMSPropAdagrad2017 that can be
   shown to perform better see
   cite:bushaevUnderstandingRMSpropFaster2018). The specifics of
   Neural Networks are beyond the scope of this paper (see
   cite:hmkcodeBackpropagationStepStep or more generally cite:pictonNeuralNetworks1994).

*** The Ranknet Method

   The Ranknet method is concerned with a value \(p_{ij}\) that
   measures the probability that an observation \(i\) is ranked higher
   than an observation \(j\).

   A Neural Network (\(n\)) is trained to return a value
   \(s_k\) from a feature vector \(\mathbf{X}_k\):

   \[n(\mathbf{X}_i) = s_i \quad \exists k\]
  So as to minimise the error of:


  \[
  p_{ij} = \frac{1}{1+e^{\sigma \cdot (s_i-s_j)}} \quad \exists \sigma
  \in \mathbb{R}
  \]
  
*** Implementation
    The first step is to create a simple data set and design a neural
    network that can classify that data set, this can then be extended.
    
** TODO How to clone 
   How can the reader clone this onto there machine?

   put on the summer repo then provide instructions to clone this
   working example onto there machine to try it out.
** TODO Blobs
** TODO Moons
** TODO Optimisers
** TODO Batches
** TODO Wine
** TODO Rank Wiki Articles

* Conclusion

* Further Research

  - Apply this to documents to get a sorted list.
  - The "Quicksort" algorithm likely needs a random pivot to be efficient cite:timroughgardenQuicksortOverview2017

* Text and References
Fractals are complex shapes that often occur from natural processes, in this
report we hope to investigate the emergence of patterns and complex structures
from natural phenomena. We begin with an investigation into fractals and the
concept of dimension and then discuss links between fractal patterns and natural
processes.

This is a Reference cite:tuGraphBasedSemiSupervisedNearestNeighbor2016a and another cite:nicodemiIntroductionAbstractAlgebra2007a and yet another cite:christopherburgesRankNetLambdaRankLambdaMART2010.

* Fractals
Images are shown in figure [[imtest]].

# #+NAME: imtest
# #+CAPTION: This is a test image showing the outline of a Julia set
# #+attr_html: :width 400px
# #+attr_latex: :width 0.5\textwidth
[[# file:media/outline-rabbit.png]]

* Appendix
  
** Search Engines
   :PROPERTIES:
   :CUSTOM_ID: search-engines-list
   :END:
There are many open source search engines available , a cursory review
found the following popular projects:

- [[https://github.com/cyclaero/zettair][Zettair]] (=C=) cite:jansenCyclaeroZettair2020
- [[https://github.com/apache/lucene-solr][Apache lucene/Solr]] (=Java=) cite:apachesoftwarefoundationLearningRankApache2017
  - Implemented by [[https://sourceforge.net/p/docfetcher/code/ci/master/tree/][DocFetcher]] cite:docfetcherdevelopmentteamDocFetcherFastDocument
- [[https://github.com/sphinxsearch/sphinx][Sphinx]] (=C++=) cite:yurischapovSphinxsearchSphinx2021
- [[https://github.com/kevinduraj/xapian-search][Xapian]] (=C++=) cite:ollybettsXapianXapian2021
  - Implemented by [[https://www.lesbonscomptes.com/recoll/][Recoll]] cite:jean-francoisdockesRecollUserManual

More Modern Search engines include:

- [[https://github.com/olivernn/lunr.js/][LunrJS]]  (=JS=) cite:nightingaleOlivernnLunrJs2021
- [[https://github.com/blevesearch/bleve][Bleve Search]] (=Go=) cite:martyschochBleveSearchDocumentation
- [[https://github.com/go-ego/riot][Riot]] (=Go=) cite:vzGoegoRiot2021
- [[https://github.com/tantivy-search/tantivy][Tantivy]] (=Rust=) cite:clementrenaultMeilisearchMeiliSearch2021
- [[https://github.com/andylokandy/simsearch-rs][SimSearch]] (=Rust=) cite:lokAndylokandySimsearchrs2021

* Footnotes

[fn:3] 

[fn:2] *BCE* /Binary Cross Entropy/ 

[fn:1] *RMSE* /Root Mean Square Error/  
