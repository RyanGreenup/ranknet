#+TITLE: Implementing of RankNet
:PREAMBLE:
#+OPTIONS: broken-links:auto todo:nil H:9 tags:t tex:t
#+STARTUP: overview
#+AUTHOR: Ryan Greenup
#+PLOT: title:"Citas" ind:1 deps:(3) type:2d with:histograms set:"yrange [0:]"
# #+TODO: TODO IN-PROGRESS WAITING DONE
#+CATEGORY: TAD
:END:
:HTML:
#+INFOJS_OPT: view:info toc:3
#+HTML_HEAD_EXTRA: <link rel="stylesheet" type="text/css" href="./resources/style.css">
# #+CSL_STYLE: /home/ryan/Templates/CSL/nature.csl
:END:
:R:
#+PROPERTY: header-args:R :session TADMain :dir ./ :cache yes :eval never-export :exports both
#+PROPERTY: :eval never
# exports: both (or code or whatever)
# results: table (or output or whatever)
:END:
:LATEX:
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper,11pt,twoside]
#+LATEX_HEADER: \IfFileExists{./resources/style.sty}{\usepackage{./resources/style}}{}
#+LATEX_HEADER: \IfFileExists{./resources/referencing.sty}{\usepackage{./resources/referencing}}{}
#+LATEX_HEADER: \addbibresource{../resources/references.bib}
#+LATEX_HEADER: \usepackage[mode=buildnew]{standalone}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{decorations.fractals}
#+LATEX_HEADER: \usetikzlibrary{lindenmayersystems}
:END:
@@latex: \newpage @@

* Introduction
  Ranknet is an approach to /Machine-Learned Ranking (often refered to
  as "//Learning to Rank//" cite:liuLearningRankInformation2009) that
  began development at Microsoft from 2004 onwards
  cite:christopherburgesRankNetRankingRetrospective2015, although
  previous work in this area had already been undertaken as early as
  the 90s (see generally
  cite:fuhrProbabilisticModelsInformation1992,fuhrOptimumPolynomialRetrieval1989,fuhrProbabilisticModelsInformation1992,geyInferringProbabilityRelevance1994,wongLinearStructureInformation1988)
  these earlier models didn't perform well compared to more modern
  machine learning techniques
  [[cite:manningIntroductionInformationRetrieval2008][\S 15.5]].

  Information retrieval is an area that demands effective ranking of
  queries, although straight-forward tools such as =grep=, relational
  databases (e.g. sqlite, MariaDB, PostgreSql) or NoSQL (e.g. CouchDB,
  MongoDB) can be used to retrieve documents with matching characters
  and words, these methods do not perform well in real word tasks
  across large collections of documents because they do not provide
  any logic to rank results (see generally
  cite:viksinghComparisonOpenSource2009).


* Motivation

  Search Engines implement more sophisticated techniques to rank
  results, one such example being TF-IDF weighting
  cite:martyschochBleveSearchDocumentation , well established
  search engines such as /Apache Lucene/
  cite:apachesoftwarefoundationLearningRankApache2017 and /Xapian/
  cite:jamesaylettGSoCProjectIdeasLearningtoRankStabilisationXapian2019,
  however, 
  are implementing Machine-Learned Ranking in order to improve results.

  This paper hopes to serve as a general introduction to the implementation
  of the Ranknet technique to facilitate developers of search engines in
  more modern languages (i.e. =Go= and =Rust=) in implementing
  it. This is important because these more modern languages are more
  accessible cite:huntThesisSubmittedPartial
  and memory safe cite:perkelWhyScientistsAre2020 than C/C++
  respectfully, without significantly impeding performance; this will
  encourage contributors from more diverse backgrounds and hence
  improve the quality of profession-specific tooling.

  
  For a non-comprehensive list of actively maintained search engines,
  see \S [[#search-engines-list]] of the appendix.

* Implementation

  

    # A lot of data cannot be clearly categorised or quantified even if there
    # is a capacity to compare different samples, the motivating example
    # is a collection of documents, it might be immediately clear to the
    # reader which documents are more relevant than others, even if the
    # reader would not be able to quantify a "relevance score" for each
    # document.

    # By training a model to identify a more relevant document, a ranking
    # can be applied to the data.

    # An example of this might be identifying documents in a companies
    # interwiki that are relevant for new employees, by training the model
    # to rank whether one document is more relevant than an other,
    # ultimately an ordered list of documents most relevant for new
    # employees could be created.


   Neural Networks 

  Ranking/ is the process of applying machine learning algorithms to
  ranking problems, it .

  This implementation will first apply the approach to a simple data
  set so as to clearly demonstrate that the approach works, following
  that the model will be extended to support wider and more complex
  data types before finally being implemented on a corpus of documents.

** Neural Networks

   The Ranknet method is typically implemented using a Neural Networks
   [fn:3],
   although other machine learning techniques can also be used
   [[cite:christopherburgesRankNetRankingRetrospective2015][p. 1]],
   Neural Networks are essentially a collection of different
   regression models and classifiers that are fed into one another to create a
   non-linear classifier, a loss function is used to measure the
   performance of the model with respect to the parameters
   (e.g. RMSE [fn:1] or BCE [fn:2]) and the parameters are adjusted so
   as to reduce this error by using the /Gradient Descent Technique/
   (although there are other optimisation algorithms such as RMSProp
   and AdaGrad cite:mukkamalaVariantsRMSPropAdagrad2017 that can be
   shown to perform better, see
   cite:bushaevUnderstandingRMSpropFaster2018). The specifics of
   Neural Networks are beyond the scope of this paper (see
   cite:hmkcodeBackpropagationStepStep or more generally cite:pictonNeuralNetworks1994).

*** The Ranknet Method

   The Ranknet method is concerned with a value \(p_{ij}\) that
   measures the probability that an observation \(i\) is ranked higher
   than an observation \(j\).

   A Neural Network (\(n\)) is trained to return a value
   \(s_k\) from a feature vector \(\mathbf{X}_k\):

   \[n(\mathbf{X}_i) = s_i \quad \exists k\]
  So as to minimise the error of:


  # \[
  # p_{ij} = \frac{1}{1+e^{\sigma \cdot (s_i-s_j)}} \quad \exists \sigma
  # \in \mathbb{R}
  # \]
  



 \begin{align} 
  p_{ij} &= \mathrm{sig}\left(\sigma, (s_i-s_j) \right) \quad \exists \sigma \in \mathbb{R} \\
  &\text{where:} \nonumber \\
  &\quad  \mathrm{sig}\left(\sigma, x\right) = \frac{1}{1+e^{\sigma \cdot x}} 
 \end{align} 
  
    
    
**** Version Control
     The implementation in this paper corresponds to the =walkthrough= branch
     of the =git= repository used in production of this work, id values
     (e.g. =:08db5b0:=) will be appended to titles to denote specific
     changes made in that section. See \S [[#version-control-repo]] for
     more specific guidance.

**** Code listings     
     The code listings provided will use a standard set of import
     statements (see \S [[#standard-import]] ) and so they will be
     omitted from the listings, for more comprehensive guidance on
     implementing this code refer to the [[https://crmds.github.io/CRMDS-HDR-Training-2020/][documentation page]][fn:5] that
     accompanies the =git= repo.

** TODO Creating Data                                                           :cf9ab26:
    The first step is to create a simple data set and design a neural
    network that can classify that data set, the data set generated
    should have two classes of data (this could be interpreted as
    relevant and irrelevant documents given the features or principle
    components of a data set), this can be implemented using sci kit
    learn as shown below and visualized[fn:6] in figure [[sim-data]].[fn:13]


    In order to fit a Neural Network the /PyTorch/ package can be used
    cite:NEURIPS2019_9015, this will allow the gradients of the neural
    network to be calculated numerically without needing to solve for
    the partial derivatives, hence the data will need to be in the
    form of tensors.

    # #+NAME: sample-data-plot
    # #+CAPTION: Generate Sample of Data for Classification
    #+begin_src python
      def make_data(create_plot=False, n=1000, dtype=torch.float, dev="cpu", export=""):
	  X, y = datasets.make_blobs(n, 2, 2, random_state=7)
	  # X, y = datasets.make_moons(n_samples=n, noise=0.1, random_state=0) # Moons Data for later

	  # Save the data somewhere if necessary
	  if export != "":
	      export_data(X, y, export)

	  # Reshape the data to be consistent
	  y = np.reshape(y, (len(y), 1))  # Make y vertical n x 1 matrix.

	  # -- Split data into Training and Test Sets --------------------
	  data = train_test_split(X, y, test_size=0.4)

	  if(create_plot):
	      # Create the Scatter Plot
	      plt.scatter(X[:, 0], X[:, 1], c=y)
	      plt.title("Sample Data")
	      plt.show()

	  # Make sure we're working with tensors not mere numpy arrays
	  torch_data = [None]*len(data)
	  for i in range(len(data)):
	      torch_data[i] = torch.tensor(data[i], dtype=dtype, requires_grad=False)

	  return torch_data

      # Set Torch Parameters
      dtype = torch.float
      dev = test_cuda()

      # Generate the Data
      X_train, X_test, y_train, y_test = make_data(
	  n=int(300/0.4), create_plot=True, dtype=dtype, dev=dev, export = "/tmp/simData.csv")
    #+end_src


    #+BEGIN_SRC R :exports results :results output graphics file :file SimulatedData.png :eval never
      library(tidyverse)
      data  <- read_csv("/tmp/simData.csv")
      (myplot <-  ggplot(data, aes(x = x1, y = x2, col = factor(y))) +
                        geom_point(size = 3) +
                        theme_classic() +
                        labs(col = "Relevance", x = "PC1", y = "PC2",
                             title = "Simulated Data"))
    #+END_SRC

    #+NAME: sim-data
    #+CAPTION: Generated data, output classes denote document relevance and the axis features or principle components
    #+attr_html: :width 400px
    #+attr_latex: :width 0.4\textwidth 
    #+RESULTS[5d70d2cd555504ec65f5867c4d29faff40c5763c]:
    [[file:SimulatedData.png]]

** Creating a Neural Network                                                    :7291112:
   :PROPERTIES:
   :CUSTOM_ID: creating-neural-network
   :END:
   A Neural Network model can be designed as a class, here a 2-layer
   model using Sigmoid functions has been described, this design was
   chosen for it's relative simplicity:

   #+begin_src python
     class three_layer_classification_network(nn.Module):
         def __init__(self, input_size, hidden_size, output_size, dtype=torch.float, dev="cpu"):
	     super(three_layer_ranknet_network, self).__init__()
	     self.wi = torch.randn(input_size, hidden_size,
				   dtype=dtype,
				   requires_grad=True,
				   device=dev)
	     self.wo = torch.randn(hidden_size, output_size,
				   dtype=dtype,
				   requires_grad=True,
				   device=dev)

	     self.bi = torch.randn(hidden_size,
				   dtype=dtype,
				   requires_grad=True,
				   device=dev)
	     self.bo = torch.randn(output_size,
				   dtype=dtype,
				   requires_grad=True,
				   device=dev)

	     self.σ = torch.randn(1, dtype=dtype, requires_grad=True, device=dev)

	     self.losses = []       # List of running loss values
	     self.trainedQ = False  # Has the model been trained yet?

         def forward(self, x):
             x = torch.matmul(x, self.wi).add(self.bi)
             x = torch.sigmoid(x)
             x = torch.matmul(x, self.wo).add(self.bo)
             x = torch.sigmoid(x)
             return x

         def loss_fn(self, x, y):
             y_pred = self.forward(x)
             return torch.mean(torch.pow((y-y_pred), 2))

         def misclassification_rate(self, x, y):
             y_pred = (self.forward(x) > 0.5)
             return np.average(y != y_pred)
   #+end_src
 
   A model can then be instantiated, a =2-3-1=
   model has, arbitrarily, been implemented in this case:[fn:7]

   #+begin_src python :results output
     # Set Seeds
     torch.manual_seed(1)
     np.random.seed(1)

     # Set Torch Parameters
     dtype = torch.float
     dev = test_cuda()

     # Make the Data
     X_train, X_test, y_train, y_test = make_data(
	 n=100, create_plot=True, dtype=dtype, dev=dev)

     # Create a model object
     model = three_layer_classification_network(
	 input_size=X_train.shape[1], hidden_size=2, output_size=1, dtype=dtype, dev=dev)

     # Send some data through the model
     print("\nThe Network input is:\n---\n")
     print(X_train[7,:], "\n")
     print("The Network Output is:\n---\n")
     print(model.forward(X_train[7,:]).item(), "\n")

   #+end_src

   #+begin_example
     The Network input is:
     ---

     tensor([-1.5129,  2.9332]) 

     The Network Output is:
     ---

     0.22973690927028656 
   #+end_example
   
** Train the Model with Gradient Descent                                        :7d46636:
   Now that the model has been fit, a method to train the model can be
   implmented [fn:8]:
   #+begin_src python
     class three_layer_classification_network(nn.Module):
	 # __init__ method goes here, see above
	 # ...
	 # ...

	 def train(self, x, target, η=30, iterations=2e4):
	     bar = Bar('Processing', max=iterations) # progress bar
	     for t in range(int(iterations)):

		 # Calculate y, forward pass
		 y_pred = self.forward(x)

		 # Measure the loss
		 loss = self.loss_fn(x, target)

		 # print(loss.item())
		 self.losses.append(loss.item())

		 # Calculate the Gradients with Autograd
		 loss.backward()

		 with torch.no_grad():
		     # Update the Weights with Gradient Descent 
		     self.wi -= η * self.wi.grad; self.wi.grad = None
		     self.bi -= η * self.bi.grad; self.bi.grad = None
		     self.wo -= η * self.wo.grad; self.wo.grad = None
		     self.bo -= η * self.bo.grad; self.bo.grad = None
		     self.σ  -= η * self.σ.grad;  self.σ.grad = None
		 bar.next()
	     bar.finish()
		     # ; Zero out the gradients, they've been used

	 # Rest of the Class Definition Below ...VVV...
   #+end_src

   With this definition the model can hence be trained in order to
   produce meaningful classifications, as shown below, this model classifies the
   points perfectly, even on the testing data, the training error 
   over time is shown in figure [[training-error-1]].

   #+begin_src python
     # Make the Data
     X_train, X_test, y_train, y_test = make_data(
	 n=100, create_plot=True, dtype=dtype, dev=dev)

     # Create a model object
     model = three_layer_classification_network(
	 input_size=X_train.shape[1], hidden_size=2, output_size=1, dtype=dtype, dev=dev)

     # Train the Model
     model.train(X_train, y_train, η=1e-2, iterations=10000)

     # Plot the losses
     plt.plot(model.losses)
     plt.title("Losses at each training iteration")
     plt.show()

     print("The testing misclassification rate is:\n")
     print(model.misclassification_rate(X_test, y_test))
   #+end_src


   #+NAME: training-error-1
   #+CAPTION: Training error, given by \(l\left( x \right) = \sum^{n}_{i= 1} \left[ \left( x_i - f\left( x_i \right)  \right)^2  \right]\), at each iteration of training
   #+attr_html: :width 50 px
   #+attr_latex: :width 0.3\textwidth
   [[./media/loss_function_initial_nn.png]]

** Implement Ranknet                                                            :f25f376:05df04f:
   Now that the model can classify the data, the implementation will
   be modified to:

   - Measure loss using a BCE function which is reported to perform better in the
     literature cite:christopherburgesRankNetRankingRetrospective2015,christopherburgesRankNetLambdaRankLambdaMART2010
   - Modify the model so that it operates pairwise, such that:
     1. Two points are identified, sent through the neural network and
        two values returned:
	  \begin{align}
	  s_i = n(\mathbf{X}_i) \label{eq:forward_single1}\\
	  s_j = n(\mathbf{X}_j) \label{eq:forward_single2}
	  \end{align}
	The network previously created can be adapted for this and
        hence the method will be renamed to =forward_single= and this
        will represent function \(n()\) implemented in
        eqref:eq:forward_single1 and eqref:eq:forward_single2
     2. These values will be combined to give a single value which is
        intended to measure the model confidence:[fn:9]

	\begin{align}
	\hat{P}_{ij} &= \mathrm{sig}\left(\sigma, (s_i-s_j)\right), \quad
	\exists \sigma \in \mathbb{R} \\
	&= \frac{1}{1+e^{\sigma \cdot (s_i-s_j)}} \label{eq:sig-comb}
	\end{align}
     3. The range of eqref:eq:sig-comb  is the interval \(\hat{P}_{ij} =
        \left[0, 1\right]\), let \(\bar{P}_{ij}\) be the known
        probability[fn:10] that \(\mathbf{X}_i \triangleright
        \mathbf{X}_j\), the simulated data has a boolean range of
        \(\bar{P}_{ij} \in \left\{0, 1\right\}\), this can be recast
        to \(\{-1, 0, 1\}\) and then linearly scaled to \(\left[0,
        1\right]\) like so:

	\begin{align}
	\bar{P}_{ij} & \leftarrow p_i - p_j \\
	\bar{P}_{ij} & \leftarrow \frac{1+\bar{P}_{ij}}{2}
	\end{align}


   These modifications only need to be made to the neural network
   class like so:

   #+begin_src python
     class three_layer_ranknet_network(nn.Module):
	 # __init__ method
	 # ...
	 # ...

	 def forward(self, xi, xj):
	     si = self.forward_single(xi)
	     sj = self.forward_single(xj)
	     out = 1 / (1 + torch.exp(-self.σ * (si - sj)))  
	     return out

	 def forward_single(self, x):
	     x = torch.matmul(x, self.wi).add(self.bi)
	     x = torch.sigmoid(x)
	     x = torch.matmul(x, self.wo).add(self.bo)
	     x = torch.sigmoid(x)

	     return x

	 def loss_fn(self, xi, xj, y):
	     y_pred = self.forward(xi, xj)
	     loss = torch.mean(-y * torch.log(y_pred) -
			       (1 - y) * torch.log(1 - y_pred))
	     return loss

	def pairwise(iterable):
	    "pairwise([1,2,3,4]) --> [(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]"
	    s = list(iterable)
	    pair_iter = chain.from_iterable(combinations(s, r) for r in [2])
	    return pair_iter

   #+end_src

   The training method must be adapted to interact with these changes
   like so:[fn:11]

   #+begin_src python
     class three_layer_ranknet_network(nn.Module):
	 # __init__ method
	 # ...
	 # ...
	 def train(self, x, target, η=1e-2, iterations=4e2):
	     self.trainedQ = True
	     # Create a progress bar
	     bar = Bar('Processing', max=iterations)
	     # Train for a number of iterations
	     for t in range(int(iterations)):
		 sublosses = []
                 # Loop over every pair of values
		 for pair in pairwise(range(len(x) - 1)):
		     xi, yi = x[pair[0], ], target[pair[0]]
		     xj, yj = x[pair[1], ], target[pair[1]]

		     # encode from {0, 1} to {-1, 0, 1}
		     y = yi - yj

		     # Scale between {0,1}
		     y = 1 / 2 * (1 + y)

		     # Calculate y, forward pass
		     y_pred = self.forward(xi, xj)

		     # Measure the loss
		     loss = self.loss_fn(xi, xj, y)
		     sublosses.append(loss.item())

		     # Calculate the Gradients with Autograd
		     loss.backward()

		     # Update the Weights with Gradient Descent
		     # ; Zero out the gradients, they've been used
		     with torch.no_grad():
			 self.wi -= η * self.wi.grad; self.wi.grad = None
			 self.bi -= η * self.bi.grad; self.bi.grad = None
			 self.wo -= η * self.wo.grad; self.wo.grad = None
			 self.bo -= η * self.bo.grad; self.bo.grad = None
			 self.σ  -= η * self.σ.grad ; self.σ.grad  = None

		 self.losses.append(np.average(sublosses))
		 bar.next()
	     bar.finish()
	     self.threshold_train(x, target, plot=False)
   #+end_src

   This can then be implemented as before with the loss function shown
   in figure [[ranknet-loss]], one of the greatest difficulties in
   implementing this, however, is that it is not simple to determine
   whether or not the model has classified the data well:[fn:12] 

   #+begin_src python
     # Make the Data
     X_train, X_test, y_train, y_test = make_data(
	 n=30, create_plot=True, dtype=dtype, dev=dev)

     # Create a model object
     model = three_layer_ranknet_network(
	 input_size=X_train.shape[1], hidden_size=2, output_size=1, dtype=dtype, dev=dev)

     # Train the Model
     model.train(X_train, y_train, η=1e-1, iterations=1e2)

     # Save the losses
     np.savetxt(fname="/tmp/losses.csv", X=model.losses, delimiter=',')

   #+end_src
   
    #+BEGIN_SRC R :exports results :results output graphics file :file SimulatedData.png :eval never
      library(tidyverse)
      data  <- read_csv("/tmp/simData.csv")
      (myplot <-  ggplot(data, aes(x = x1, y = x2, col = factor(y))) +
                        geom_point(size = 3) +
                        theme_classic() +
                        labs(col = "Relevance", x = "PC1", y = "PC2",
                             title = "Simulated Data"))
    #+END_SRC

** Implement sorting
   So instead of ranking, sort the values, this produces the output.

   but this is the problem, did it work? it's not clear, because even
   if the model was not trained we get the following (put them side by side).

   So this is definitely one of the hard issues.

   what would be better would be to classify data with a rating
   (i.e. wine scores), only show the model whether the wine is
   good/bad and compare the output order with the input order, that
   would be an effective way to see that it works. This was not yet
   effectively implemented.
** TODO Moons
** TODO Optimisers
** TODO Batches
** TODO Wine
** TODO Rank Wiki Articles
* TODO Difficulties
  - Don't use torch
    - Do it by hand first because it can be hard to see if the correct
      weights are being updated sensibly, making debugging very difficult.
    - R or Julia would be easier because counting from 0 get's pretty
      confusing when dealing with {1, 0}, {-1, 0, 1}.
  - Don't use misclassification rate to measure whether the ranking
    - In hindsight this is obvious, but at the time misclassification
      was a tempting metric because of it's interpretability
    was correct

    Very difficult to see if the model is working

  - A continuous function will still produce an ordered pattern in
      the ranking of results, even if the model hasn't been trained,
      so visualising isn't helpful either.

  - Implement it on a data set that already has order, obfuscate the
      order and then contrast the results
    - or use a measurement

  - Plot the loss function of the training data live, the model is
    slow to train and waiting for it to develop was a massive time
    drain.
    


* Further Research

  
** Practical Improvements

  - Apply this to documents to get a sorted list, like the wine data
  - The "Quicksort" algorithm likely needs a random pivot to be efficient cite:timroughgardenQuicksortOverview2017

** Evaluate performance improvements

  It is still not clear how the
  performance of Ranknet compares to traditional approaches
  implemented by search engines (see \S [[#search-engines-list]]), further
  study would ideally:

  - Write a program to query a corpus of documents using an existing search engine.
    - Or possibly just implement TF-IDF weighting in order to remove variables.
  - Extend the program to implement machine learned ranking
  - Measure and contrast the performance of the two models to see
    whether there are any significant improvements.

  This could be implemented with TREC datasets
  cite:usnationalinstituteofstandardsandtechnologyTextREtrievalConference
  using a cummulated-gain cost function
  cite:jarvelinCumulatedGainbasedEvaluation2002 as demonstrated in
  previous work cite:viksinghComparisonOpenSource2009.

** Evaluate alternative machine learning models
   :PROPERTIES:
   :CUSTOM_ID: machine-learning-models
   :END:
   i.e. can SVM's or trees be used instead of neural networks?

* Conclusion

* Text and References
Fractals are complex shapes that often occur from natural processes, in this
report we hope to investigate the emergence of patterns and complex structures
from natural phenomena. We begin with an investigation into fractals and the
concept of dimension and then discuss links between fractal patterns and natural
processes.

This is a Reference cite:tuGraphBasedSemiSupervisedNearestNeighbor2016a and another cite:nicodemiIntroductionAbstractAlgebra2007a and yet another cite:christopherburgesRankNetLambdaRankLambdaMART2010.

* Fractals
Images are shown in figure [[imtest]].

# #+NAME: imtest
# #+CAPTION: This is a test image showing the outline of a Julia set
# #+attr_html: :width 400px
# #+attr_latex: :width 0.5\textwidth
[[# file:media/outline-rabbit.png]]

* Appendix
  
** Search Engines
   :PROPERTIES:
   :CUSTOM_ID: search-engines-list
   :END:
There are many open source search engines available , a cursory review
found the following popular projects:

- [[https://github.com/cyclaero/zettair][Zettair]] (=C=) cite:jansenCyclaeroZettair2020
- [[https://github.com/apache/lucene-solr][Apache lucene/Solr]] (=Java=) cite:apachesoftwarefoundationLearningRankApache2017
  - Implemented by [[https://sourceforge.net/p/docfetcher/code/ci/master/tree/][DocFetcher]] cite:docfetcherdevelopmentteamDocFetcherFastDocument
- [[https://github.com/sphinxsearch/sphinx][Sphinx]] (=C++=) cite:yurischapovSphinxsearchSphinx2021
- [[https://github.com/kevinduraj/xapian-search][Xapian]] (=C++=) cite:ollybettsXapianXapian2021
  - Implemented by [[https://www.lesbonscomptes.com/recoll/][Recoll]] cite:jean-francoisdockesRecollUserManual

More Modern Search engines include:

- [[https://github.com/olivernn/lunr.js/][LunrJS]]  (=JS=) cite:nightingaleOlivernnLunrJs2021
- [[https://github.com/blevesearch/bleve][Bleve Search]] (=Go=) cite:martyschochBleveSearchDocumentation
- [[https://github.com/go-ego/riot][Riot]] (=Go=) cite:vzGoegoRiot2021
- [[https://github.com/tantivy-search/tantivy][Tantivy]] (=Rust=) cite:clementrenaultMeilisearchMeiliSearch2021
- [[https://github.com/andylokandy/simsearch-rs][SimSearch]] (=Rust=) cite:lokAndylokandySimsearchrs2021

  
*** Fuzzy String Match
    Somewhat related are programs that rank string similarity, such programs don't tend
    to perform well on documents however (so for example these would
    be effective to filter document titles but would not be useful for
    querying documents):

    - [[https://github.com/junegunn/fzf][=fzf=]] cite:choiJunegunnFzf2021
    - [[https://github.com/jhawthorn/fzy][=fzy=]] cite:hawthornJhawthornFzy2021
    - [[https://github.com/peco/peco][=peco=]] cite:lestrratPecoPeco2021
    - [[https://github.com/lotabout/skim][Skim]] cite:zhangLotaboutSkim2021
    - [[https://github.com/lotabout/skim][=go-fuzzyfinder=]] cite:ktrKtr0731Gofuzzyfinder2021
    - [[https://github.com/lotabout/skim][Swiper]] cite:krehelAboaboSwiper2021

** Import Statements
   :PROPERTIES:
   :CUSTOM_ID: standard-import
   :END:
The following import statements were included, where used, [fn:4]
separate scripts were used to make the model as modular as possible,
such corresponding inputs have also been listed:

#+begin_src python
  # Import Packages
  from itertools import chain
  from itertools import combinations
  from itertools import tee
  from progress.bar import Bar
  import math as m
  import matplotlib.pyplot as plt
  import numpy as np
  import random
  import sys
  import sys
  import torch
  import torch
  from torch import nn

  # Sepereate Scripts lcated below main
  from ranknet.test_cuda import test_cuda
  from ranknet.make_data import make_data
  from ranknet.neural_network import three_layer_ranknet_network
  from ranknet.quicksort import quicksort
#+end_src
   
** Export Data Method
   :PROPERTIES:
   :CUSTOM_ID: export-data-function
   :END:
   The data was exported by printing the values to a text file like
   so:

   #+begin_src python
     def export_data(X, y, export):
	 try:
	     os.remove(export)
	     print("Warning, given file was over-written")
	 except:
	     pass

	 with open(export, "a") as f:
	     line = "x1, x2, y \n"
	     f.write(line)
	     for i in (range(X.shape[0])):
		 line = str(X[i][0]) + ", " + str(X[i][1]) + ", " + str(y[i]) + "\n"
		 f.write(line)
	 print("Data Exported")


   #+end_src

** Version Control Repository
   :PROPERTIES:
   :CUSTOM_ID: version-control-repo
   :END:

   The =git= repository used in production of this code is currently
   available on /GitHub/ at [[https://github.com/CRMDS/CRMDS-HDR-Training-2020][github.com/CRMDS/CRMDS-HDR-Training-2020]], in
   order to get a local copy, execute the following commands (=bash=): 

   #+begin_src bash
     # Clone the repository
     git clone https://github.com/CRMDS/CRMDS-HDR-Training-2020

     # Change to the subdirectory
     cd CRMDS-HDR-Training-2020/ranknet

     # Checkout the Walkthrough branch
     git checkout walkkthrough

     # list the changes
     git log
   #+end_src

   Consider the use of tools like [[https://magit.vc/][magit]] cite:MagitMagit2008 and
   [[https://github.com/emacsmirror/git-timemachine][git-timemachine]] cite:peterstiernstromEmacsmirrorGittimemachine2014 (or
   [[https://marketplace.visualstudio.com/items?itemName=eamodio.gitlens][GitLens]] cite:amodioEamodioVscodegitlens2016 and [[https://marketplace.visualstudio.com/items?itemName=bee.git-temporal-vscode][git-temporal]]
   cite:beewilkersonGittemporalGittemporalMono2018 in VsCode) in order
   to effectively preview the changes at each step, alternatively a
   pager like [[https://github.com/sharkdp/bat][bat]] cite:peterSharkdpBat2018 can also be used with something like [[https://github.com/junegunn/fzf][fzf]]
   cite:choiJunegunnFzf2021 like so:

   #+begin_src bash
     git log | grep '^commit' | sed 's/^commit\ //' |\
         fzf --preview 'git diff {}^! |\
          bat --color always'  
   #+end_src

*** Version Control Log for Walkthrough
    :PROPERTIES:
    :CUSTOM_ID: git-log
    :END:

 | */Commit ID/* | */Message/*                                              |
 |-------------+--------------------------------------------------------|
 | =ed5f4cf=     | /Initial Commit/                                         |
 | =075acf9=     | /Walkthrough Initial Commit/                             |
 | =cf9ab26=     | /Generate data to use for classification/                |
 | =7291112=     | /Create a Neural Network Model/                          |
 | =7d46636=     | /Implement gradient descent to train neural network/     |
 | =f25f376=     | /Adapt Neural Network to perform Ranking/                |
 | =42509ab=     | /Implement sorting algorithm to visualise ranking order/ |
 | =05df04f=     | /Adapt Neural Network to perform Ranking/                |
 | =99b390a=     | /Implement sorting algorithm to visualise ranking order/ |
 | =473dce3=     | /Implement optimizer to replace mere gradient descent/   |
 | =4141e92=     | /Train Model using Batches not entire dataset/           |
 | =a2671a6=     | /Format code to make it more readable/                   |
 | =d11e607=     | /plot and only train on different ranked pairs/          |
   
**** COMMENT Export
    #+begin_example
      commit d11e6076cb1e7838a978158682114948c013b146
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Fri Feb 19 16:34:45 2021 +1100

	  plot and only train on different ranked pairs

      commit a2671a6bd33b0fcb50f83d66326f55181c50ce5a
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Wed Feb 17 17:30:09 2021 +1100

	  Format code to make it more readable

      commit 4141e925f6ff61dc5b95dbcc1556699cb254ee98
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Wed Feb 17 17:29:28 2021 +1100

	  Train Model using Batches not entire dataset

      commit 473dce38554598aee49a4ebe042ce8dd0abfba0c
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Wed Feb 17 16:08:43 2021 +1100

	  Implement optimizer to replace mere gradient descent

      commit 99b390a81a8819205a16cc0df87ac0e1fdb6b267
      Merge: 05df04f 42509ab
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Wed Feb 17 16:07:05 2021 +1100

	  Implement sorting algorithm to visualise ranking order

      commit 05df04f3620e6bcce179ae3d2ad84fc7756e2819
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Wed Feb 17 16:00:12 2021 +1100

	  Adapt Neural Network to perform Ranking

      commit 42509abfe76a8583520c1ad577c28ed49a5cebde
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 16:17:59 2021 +1100

	  Implement sorting algorithm to visualise ranking order

      commit f25f3768b44f884409298f6f62c6bd430bc78574
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 16:12:18 2021 +1100

	  Adapt Neural Network to perform Ranking

      commit 7d46636dd1008bf48e58978d2b075f13a31bd765
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 15:30:37 2021 +1100

	  Implement gradient descent to train neural network

      commit 7291112447daee631ece7583b4e94a57ab428e25
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 15:10:03 2021 +1100

	  Create a Neural Network Model

      commit cf9ab26ae9282f77ffd183bb0d71324280dd5323
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 14:50:01 2021 +1100

	  Generate data to use for classification

      commit 075acf96e24a288acc51f6467ee1c1fb10353805
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Tue Feb 16 14:42:01 2021 +1100

	  Walkthrough Initial Commit

      commit ed5f4cfdbed3751b8a778c15a542356005222b22
      Author: Ryan Greenup <exogenesis@protonmail.com>
      Date:   Fri Jan 8 10:57:30 2021 +1100

	  Initial Commit

    #+end_example


* Footnotes

[fn:13] Visualisations for this Report were implemented using
=org-babel= cite:dominikOrgModeReference2018 inside /Emacs/
cite:stallmanGNUEmacsManual2002 to call */R/*
cite:rcoreteamLanguageEnvironmentStatistical2021 with /GGPlot2/
cite:wickhamGgplot2ElegantGraphics2016a (and /Tidyverse/
cite:wickhamWelcomeTidyverse2019 generally), the source code for this
is avaliable in the report manuscript available in the =git= repository
available at [[https://github.com/RyanGreenup/ranknet/blob/main/Report/Report.org][github.com/RyanGreenup/ranknet/blob/main/Report/Report.org]]

[fn:12] A naive misclassification method was implemented (=f25f376=),
but it was not very insightful and so was omitted from this report.

[fn:11] Note the definition of the =pairwise= function, this was
incorrectly implemented initially (=f25f376=) and rectified shortly
after (=05df04f=). see [[#git-log]]

[fn:10] Note the convention that the symbols \(\triangleleft, \enspace \triangleright\) have been adopted to denote the ranking of two observations,
analogous to \(<, \enspace >\)

[fn:9] This value is a measurement of the models "confidence" but
could be extended to represent the "measured probability" of one item
being ranked higher than an other (e.g. the probability that a person
would rank one type of wine as better than the other in a random
sample).
 
[fn:8] This class definition is incomplete and serves only to show the
method definition corresponding to the original class shown in \S
[[#creating-neural-network]]


[fn:7] note that the model has not yet been trained, the weights are
random and the model output is not related to the data at all.

[fn:6] See \S [[#export-data-function]] for the specific method definition used to
export the data to a =csv.=  

[fn:5] [[https://crmds.github.io/CRMDS-HDR-Training-2020/][crmds.github.io/CRMDS-HDR-Training-2020/]]

[fn:4] Including =import= statements where they are not used is fine,
other than complaints from a /linter/ following /PEP/
cite:nickcoghlanPEPStyleGuide2001 (e.g. [[https://pypi.org/project/autopep8/][autopep]]
cite:hattoriAutopep8ToolThat) the code will function just fine.

[fn:3] An early goal of this research was to evaluate the performance
  of different machine learning algorithms to implement the Ranknet
  method, as well as contrasting this with simple classification
  approaches, this research however is still ongoing,  see \S
  [[#machine-learning-models]]

[fn:2] *BCE* /Binary Cross Entropy/ 

[fn:1] *RMSE* /Root Mean Square Error/  
